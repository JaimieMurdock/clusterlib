\documentclass{beamer}
\usetheme{CambridgeUS}

\usepackage{minted}

\title{Categorization}
\author{Jaimie Murdock}
\institute[IU COGS]{
    IU Cognitive Science Program\\
    810 Eigenmann Hall\\
    \texttt{jammurdo@indiana.edu}
    }
\date{November 15, 2011}

\begin{document}
% Title Page
\frame{\titlepage}
\frame{\tableofcontents}
\section{Introduction}
\begin{frame}
"Issues related to concepts and categorization are nearly ubiquitous in
psychology because of people's natural tendancy to perceive a thing as
something." - Goldstone \& Kersten 2003
\end{frame}

\begin{frame}
\frametitle{Different names for the same thing...}
\begin{itemize}
  \item{Categorization}
  \item{Classification \tiny{(machine learning)}}
  \item{Clustering \tiny{(data mining)}}
  \item{Partitioning \tiny{(mathematics)}}
  \pause
  \item{Chunking \tiny{(memory)}}
  \item{Object Recognition \tiny{(vision)}}
  \item{Semantics \tiny{(linguistics)}}
  \item{Named Entity Recognition \tiny{(natural language processing)}}
\end{itemize}

\end{frame}

\subsection{Definitions}
\begin{frame}
\frametitle{What is categorization?}

\begin{itemize}
  \item{The assignment of concepts to categories}
  \item{``Seeing something as X'' - Wittgenstein, \textit{Philosophical Investigations}}
  
  \pause
  \bigskip

  \item{\textbf{What is a concept?}\\
        Whatever psychological state signifies thoughts of X}
  \item{\textbf{What is a category?}\\
        All entities that are appropriately categorized as X}
\end{itemize}
\end{frame}

\subsection{Models}
\begin{frame}
\frametitle{Prototypes vs. Exemplars}
\begin{columns}
\begin{column}{.5\textwidth}
\textbf{Prototype Model}\\
Do concepts determine categories? (Lakoff 1987)
\end{column}
\pause
\begin{column}{.5\textwidth}
\textbf{Exemplar Model}\\
Do categories determine concepts? (Nosofsky 1984)
\end{column}
\end{columns}
\end{frame}

\subsection{Utility}
\begin{frame}
\frametitle{Why do we categorize?}
\begin{itemize}
  \item{Components of thought}
  \pause
  \item{Inductive Predictions}
  \pause
  \item{Communication}
  \pause
  \item{Cognitive Economy}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Equivilence Classes}
Distinguishable stimuli can become treated as the same thing once they are placed in the same category (Sidman 1994)\\

\bigskip
\pause

\textbf{Biology} - taxonomy (kingdom, phylum, class, order, family, genus, species)\\

\bigskip
\pause

\textbf{Things to remove from a burning house} - photos, babies, cats\\

\bigskip
\pause

Equivilence classes may not be uniquely human - sea lions (Schusterman, Reichmuth, Kastak 2000)
\end{frame}

\subsection{Representations}
\begin{frame}
\frametitle{Representations}
How are categories represented?

\begin{itemize}
  \item{rules}
  \pause
  \item{exemplars}
  \pause
  \item{prototypes}
  \pause
  \item{boundaries}
% TODO: Insert Figure 22.1
\end{itemize}
\end{frame}

\section{Algorithms}
\subsection{Introduction}
\begin{frame}
\frametitle{Algorithms}
A process to assign concepts to categories\\

\pause

\begin{itemize}
  \item{k-means Nearest Neighbors \tiny{(MacQueen 1967)}}
  \item{QT-clust \tiny{(Heyer et al. 1999)}}
  \item{Information Theoretic Clustering \tiny{(Gokcay \& Princip\'{e} 2002)}}
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Components}
Two key decisions in clustering:
\begin{columns}
\begin{column}{.5\textwidth}
\textbf{distance function}
\begin{itemize}
  \item Euclidean distance
  \item semantic similarity
  \item cross-entropy
\end{itemize}
\end{column}
\begin{column}{.5\textwidth}
\textbf{cluster assignment}
\begin{itemize}
  \item nearest neighbor
  \item minimal diameter
  \item maximize cross-cluster distance
\end{itemize}
\end{column}
\end{columns}
\end{frame}

\subsection{k-means Nearest Neighbors}
\begin{frame}
\frametitle{k-means Nearest Neighbors}
Given $n$ items, place into $k$ groups\\

\bigskip

\textbf{Initialize:} Pick $k$ centroids\\
\textbf{Assign:} Assign items to nearest centroid\\
\textbf{Update:} Recalculate centroids\\

\bigskip

Repeat until convergence of assignment

\end{frame}

\begin{frame}[fragile]
\frametitle{Data Structures}
\begin{minted}[fontsize=\footnotesize]{python}
class Concept(object):
    # initialize the wrapper
    def __init__(self, value):
        self.value = value
        self._cluster = None
        self._previous_cluster = None

    # Properties to track cluster assignments
    @property
    def cluster(self):
        return self._cluster
        
    @cluster.setter
    def cluster(self, value):
        """ Track previous cluster assignment auto-magically. """
        self._previous_cluster = self._cluster
        self._cluster = value
\end{minted}
\end{frame}

\begin{frame}[fragile]
\frametitle{The Main Loop}
\begin{minted}[fontsize=\footnotesize]{python}
def kmeans(k, population, min_delta=0):
    # initialize centroids with random members of the population
    centroids = [random.choice(population).value for i in range(k)]
   
    # delta is the number of elements that switch cluster
    # since all members will be changing on the first round,
    # we initialize delta to the length of the population
    delta = len(population)

    # test for convergence
    while delta > min_delta:
        # assign population to clusters
        assign_clusters(population, centroids)
        
        # get number of elements which switched cluster
        delta = len([x for x in population 
                         if x.cluster != x.previous_cluster])

        # update centroids
        centroids = update_centroids(population, centroids)
\end{minted}
\end{frame}

\begin{frame}[fragile]
\frametitle{Assignment}
\begin{minted}[fontsize=\footnotesize]{python}
def assign_clusters(population, centroids):
    for x in population:
        # calculate distance to each centroid
        distances = [distance(x.value, centroid) 
                         for centroid in centroids]

        # select the index (cluster id) of the closest cluster
        cluster, min_distance = min(enumerate(distances), 
                                    key=itemgetter(1))

        # assign the object to that cluster
        x.cluster = cluster
\end{minted}
\end{frame}

\begin{frame}[fragile]
\frametitle{Update}
\begin{minted}[fontsize=\footnotesize]{python}
def get_centroids(population, k):
    new_centroids = []

    for cluster in range(k): 
        # filter out the cluster population
        cluster_values = [x.value for x in population 
                              if x.cluster == cluster]
        # generate the new centroid by taking the average of all exemplars
        # comprising the cluster. First, sum the dimensions:
        centroid = map(sum, zip(*cluster_values))

        # then take the average:
        centroid = [dimension / len(cluster_values) 
                        for dimension in centroid]  

        # add to our list of new centroids
        new_centroids.append(centroid)
   
    return new_centroids
\end{minted}
\end{frame}

\begin{frame}[fragile]
\frametitle{The Main Loop}
\begin{minted}[fontsize=\footnotesize]{python}
def kmeans(k, population, min_delta=0):
    # initialize centroids with random members of the population
    centroids = [random.choice(population).value for i in range(k)]
   
    # delta is the number of elements that switch cluster
    # since all members will be changing on the first round,
    # we initialize delta to the length of the population
    delta = len(population)

    # test for convergence
    while delta > min_delta:
        # assign population to clusters
        assign_clusters(population, centroids)
        
        # get number of elements which switched cluster
        delta = len([x for x in population 
                         if x.cluster != x.previous_cluster])

        # update centroids
        centroids = update_centroids(population, centroids)
\end{minted}
\end{frame}

\subsection{QT--clust}
\begin{frame}
\frametitle{QT--clust}
Given $n$ items, place into groups of $\epsilon$ diameter\\

\bigskip

\textbf{Build:} for each $i \in n$, build candidate cluster $C_i$ \\
\textbf{Select:} pick largest $C_i$, remove elements from popuation \\

\bigskip

Repeat until all items are assigned.

\end{frame}

\begin{frame}[fragile]
\frametitle{Data Structures}
\begin{minted}[fontsize=\footnotesize]{python}
class Concept(object):
    # initialize the wrapper
    def __init__(self, value):
        self.value = value
        self.cluster = [self] 
        self.diameter = 0.0
    
    def _diameter_append(self, candidate):
        return max([distance(candidate.value, x.value) 
                       for x in self.cluster])
\end{minted}
\end{frame}

\begin{frame}[fragile]
\frametitle{The Main Loop}
\begin{minted}[fontsize=\footnotesize]{python}
def qt_clust(thresh, population):
    while population:
        # build candidate clusters
        for x in population:
            x.build_cluster(population, thresh)
    
        # select the largest candidate cluster
        candidate = max(population, key=lambda x: len(x.cluster))
  
        # remove elements from the population
        for x in candidate.cluster:
            population.remove(x)
    
        yield candidate
\end{minted}
\end{frame}

\begin{frame}[fragile]
\frametitle{Build}
\begin{minted}[fontsize=\footnotesize]{python}
class Concept(object):
    def build_cluster(self, population, thresh):
        # initialize the cluster
        self.cluster = [self]
        population.remove(self)

        while population:
            # find x, such that cluster diameter is minimized
            x = min(population, key=self._diameter_append)
            new_diameter = self._diameter_append(x)

            # if below quality threshold, append to cluster
            if new_diameter < thresh:
                self.cluster.append(x)
                self.diameter = new_diameter
                population.remove(x)
            else:
                # otherwise terminate the loop
                break
\end{minted}
\end{frame}

\begin{frame}[fragile]
\frametitle{The Main Loop}
\begin{minted}[fontsize=\footnotesize]{python}
def qt_clust(thresh, population):
    while population:
        # build candidate clusters
        for x in population:
            x.build_cluster(population, thresh)
    
        # select the largest candidate cluster
        candidate = max(population, key=lambda x: len(x.cluster))
  
        # remove elements from the population
        for x in candidate.cluster:
            population.remove(x)
    
        yield candidate
\end{minted}
\end{frame}

\subsection{Information Theoretic Clustering}
\begin{frame}
Given $n$ items, place into $k$ groups, minimizing the value of the cross-entropy function (CEF) \\

\bigskip

\textbf{Initialize:} Assign all items to random clusters
\textbf{Group:} for each $i \in n$, build group $G_i$ of size $M = n / k$ \\
\textbf{Reassign:} for each $i \in n$, see if switching $G_i$ reduces $CEF$, permanently switch cluster assignment for $x \in G_i$ which minimizes $CEF$ \\

\bigskip

Repeat until $CEF$ reaches minima
\end{frame}

\begin{frame}[fragile]
\frametitle{Data Structures}
\begin{minted}[fontsize=\footnotesize]{python}
class Concept(object):
    # initialize the wrapper
    def __init__(self, value):
        self.value = value
        self.cluster = None 
        self.group = [self]
    
    def _diameter_append(self, candidate):
        return min([distance(candidate.value, x.value) 
                       for x in self.group])
\end{minted}
\end{frame}

\begin{frame}[fragile]
\frametitle{The Main Loop}
\begin{minted}[fontsize=\footnotesize]{python}
def info_theory(k, population):
    # assign random clusters
    for x in population:
        x.cluster = random.choice(range(k))

    # create initial group size
    group_size = len(population) / k
   
    # grow group size exponentially while hill-climbing
    while group_size < len(population):
        # assign groups
        for x in population:
            x.make_group(population, group_size)

        hillclimb(population, group_size, k)
        group_size *= 2
\end{minted}
\end{frame}

\begin{frame}[fragile]
\frametitle{Hill Climbing}
\begin{minted}[fontsize=\footnotesize]{python}
def hillclimb(population, group_size, k):
    orig_CEF = 1.0                  # get baseline CEF
    min_CEF = CEF(population, k)    # initial min CEF

    while orig_CEF != min_CEF:
        for x in population:
            for member in x.group:
                # change cluster assignment
                member.cluster = x.cluster
    
            group_CEF = CEF(population, k)
            if group_CEF < min_CEF:
                # if CEF decreases, new min!
                min_CEF = group_CEF
            else:
                # restore previous cluster assignment
                for member in x.group:
                    member.cluster = x.previous_cluster

        orig_CEF = min_CEF    # set orig to new minima
\end{minted}
\end{frame}

\begin{frame}[fragile]
\frametitle{The Main Loop}
\begin{minted}[fontsize=\footnotesize]{python}
def info_theory(k, population):
    # assign random clusters
    for x in population:
        x.cluster = random.choice(range(k))

    # create initial group size
    group_size = len(population) / k
   
    # grow group size exponentially while hill-climbing
    while group_size < len(population):
        # assign groups
        for x in population:
            x.make_group(population, group_size)

        hillclimb(population, group_size, k)
        group_size *= 2
\end{minted}
\end{frame}

\frame{\tableofcontents}

\frame{\titlepage}

\end{document}
